{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "def load_df(csv_path='../input/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (100000, 55)\n",
      "Loaded test.csv. Shape: (100000, 53)\n"
     ]
    }
   ],
   "source": [
    "train = load_df(nrows=100000, csv_path=\"data/train.csv\")\n",
    "test = load_df(\"data/test.csv\", 100000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                        Non-Null Count   Dtype \n",
      "---  ------                                        --------------   ----- \n",
      " 0   channelGrouping                               100000 non-null  object\n",
      " 1   date                                          100000 non-null  int64 \n",
      " 2   fullVisitorId                                 100000 non-null  object\n",
      " 3   sessionId                                     100000 non-null  object\n",
      " 4   socialEngagementType                          100000 non-null  object\n",
      " 5   visitId                                       100000 non-null  int64 \n",
      " 6   visitNumber                                   100000 non-null  int64 \n",
      " 7   visitStartTime                                100000 non-null  int64 \n",
      " 8   device.browser                                100000 non-null  object\n",
      " 9   device.operatingSystem                        100000 non-null  object\n",
      " 10  device.isMobile                               100000 non-null  bool  \n",
      " 11  device.deviceCategory                         100000 non-null  object\n",
      " 12  geoNetwork.continent                          100000 non-null  object\n",
      " 13  geoNetwork.subContinent                       100000 non-null  object\n",
      " 14  geoNetwork.country                            100000 non-null  object\n",
      " 15  geoNetwork.region                             100000 non-null  object\n",
      " 16  geoNetwork.metro                              100000 non-null  object\n",
      " 17  geoNetwork.city                               100000 non-null  object\n",
      " 18  geoNetwork.networkDomain                      100000 non-null  object\n",
      " 19  totals.visits                                 100000 non-null  object\n",
      " 20  totals.hits                                   100000 non-null  object\n",
      " 21  totals.pageviews                              99993 non-null   object\n",
      " 22  totals.bounces                                48916 non-null   object\n",
      " 23  totals.newVisits                              77263 non-null   object\n",
      " 24  totals.transactionRevenue                     1399 non-null    object\n",
      " 25  trafficSource.campaign                        100000 non-null  object\n",
      " 26  trafficSource.source                          100000 non-null  object\n",
      " 27  trafficSource.medium                          100000 non-null  object\n",
      " 28  trafficSource.keyword                         44218 non-null   object\n",
      " 29  trafficSource.isTrueDirect                    30454 non-null   object\n",
      " 30  trafficSource.referralPath                    36473 non-null   object\n",
      " 31  trafficSource.adwordsClickInfo.page           2574 non-null    object\n",
      " 32  trafficSource.adwordsClickInfo.slot           2574 non-null    object\n",
      " 33  trafficSource.adwordsClickInfo.gclId          2625 non-null    object\n",
      " 34  trafficSource.adwordsClickInfo.adNetworkType  2574 non-null    object\n",
      " 35  trafficSource.adwordsClickInfo.isVideoAd      2574 non-null    object\n",
      " 36  trafficSource.adContent                       1325 non-null    object\n",
      " 37  trafficSource.campaignCode                    1 non-null       object\n",
      "dtypes: bool(1), int64(4), object(33)\n",
      "memory usage: 28.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                        Non-Null Count   Dtype \n",
      "---  ------                                        --------------   ----- \n",
      " 0   channelGrouping                               100000 non-null  object\n",
      " 1   date                                          100000 non-null  int64 \n",
      " 2   fullVisitorId                                 100000 non-null  object\n",
      " 3   sessionId                                     100000 non-null  object\n",
      " 4   socialEngagementType                          100000 non-null  object\n",
      " 5   visitId                                       100000 non-null  int64 \n",
      " 6   visitNumber                                   100000 non-null  int64 \n",
      " 7   visitStartTime                                100000 non-null  int64 \n",
      " 8   device.browser                                100000 non-null  object\n",
      " 9   device.operatingSystem                        100000 non-null  object\n",
      " 10  device.isMobile                               100000 non-null  bool  \n",
      " 11  device.deviceCategory                         100000 non-null  object\n",
      " 12  geoNetwork.continent                          100000 non-null  object\n",
      " 13  geoNetwork.subContinent                       100000 non-null  object\n",
      " 14  geoNetwork.country                            100000 non-null  object\n",
      " 15  geoNetwork.region                             100000 non-null  object\n",
      " 16  geoNetwork.metro                              100000 non-null  object\n",
      " 17  geoNetwork.city                               100000 non-null  object\n",
      " 18  geoNetwork.networkDomain                      100000 non-null  object\n",
      " 19  totals.visits                                 100000 non-null  object\n",
      " 20  totals.hits                                   100000 non-null  object\n",
      " 21  totals.pageviews                              99993 non-null   object\n",
      " 22  totals.bounces                                48916 non-null   object\n",
      " 23  totals.newVisits                              77263 non-null   object\n",
      " 24  totals.transactionRevenue                     1399 non-null    object\n",
      " 25  trafficSource.campaign                        100000 non-null  object\n",
      " 26  trafficSource.source                          100000 non-null  object\n",
      " 27  trafficSource.medium                          100000 non-null  object\n",
      " 28  trafficSource.keyword                         44218 non-null   object\n",
      " 29  trafficSource.isTrueDirect                    30454 non-null   object\n",
      " 30  trafficSource.referralPath                    36473 non-null   object\n",
      " 31  trafficSource.adwordsClickInfo.page           2574 non-null    object\n",
      " 32  trafficSource.adwordsClickInfo.slot           2574 non-null    object\n",
      " 33  trafficSource.adwordsClickInfo.gclId          2625 non-null    object\n",
      " 34  trafficSource.adwordsClickInfo.adNetworkType  2574 non-null    object\n",
      " 35  trafficSource.adwordsClickInfo.isVideoAd      2574 non-null    object\n",
      " 36  trafficSource.adContent                       1325 non-null    object\n",
      " 37  trafficSource.campaignCode                    1 non-null       object\n",
      "dtypes: bool(1), int64(4), object(33)\n",
      "memory usage: 28.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#df = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "#train = train.loc[:, (train.eq(\"not available in demo dataset\"))]\n",
    "\n",
    "# Find the columns where values are not available\n",
    "useless_cols = [col for col in train.columns if train[col].eq(\"not available in demo dataset\").all()]\n",
    "# Drop these columns from the dataframe\n",
    "train.drop(useless_cols,\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "train.info()\n",
    "\n",
    "# Find the columns where values are not available\n",
    "useless_cols = [col for col in train.columns if train[col].isna().all()]\n",
    "# Drop these columns from the dataframe\n",
    "train.drop(useless_cols,\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['socialEngagementType', 'totals.visits']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_cols = [c for c in train.columns if train[c].nunique(dropna=False)==1 ]\n",
    "const_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables not in test but in train :  {'totals.transactionRevenue', 'trafficSource.campaignCode'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables not in test but in train : \", set(train.columns).difference(set(test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = const_cols + ['sessionId']\n",
    "\n",
    "train_df = train.drop(cols_to_drop + [\"trafficSource.campaignCode\"], axis=1)\n",
    "test_df = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelGrouping\n",
      "device.browser\n",
      "device.deviceCategory\n",
      "device.operatingSystem\n",
      "geoNetwork.city\n",
      "geoNetwork.continent\n",
      "geoNetwork.country\n",
      "geoNetwork.metro\n",
      "geoNetwork.networkDomain\n",
      "geoNetwork.region\n",
      "geoNetwork.subContinent\n",
      "trafficSource.adContent\n",
      "trafficSource.adwordsClickInfo.adNetworkType\n",
      "trafficSource.adwordsClickInfo.gclId\n",
      "trafficSource.adwordsClickInfo.page\n",
      "trafficSource.adwordsClickInfo.slot\n",
      "trafficSource.campaign\n",
      "trafficSource.keyword\n",
      "trafficSource.medium\n",
      "trafficSource.referralPath\n",
      "trafficSource.source\n",
      "trafficSource.adwordsClickInfo.isVideoAd\n",
      "trafficSource.isTrueDirect\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import datetime\n",
    "\n",
    "# Impute 0 for missing target values\n",
    "train_df[\"totals.transactionRevenue\"].fillna(0.0, inplace=True)\n",
    "train_df[\"totals.pageviews\"].fillna(0.0, inplace=True)\n",
    "train_df[\"totals.bounces\"].fillna(0.0, inplace=True)\n",
    "train_df[\"totals.newVisits\"].fillna(0.0, inplace=True)\n",
    "train_y = train_df[\"totals.transactionRevenue\"].values\n",
    "train_id = train_df[\"fullVisitorId\"].values\n",
    "test_id = test_df[\"fullVisitorId\"].values\n",
    "\n",
    "\n",
    "# label encode the categorical variables and convert the numerical variables to float\n",
    "cat_cols = [\"channelGrouping\", \"device.browser\", \n",
    "            \"device.deviceCategory\", \"device.operatingSystem\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n",
    "            \"trafficSource.adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource.adwordsClickInfo.gclId\", \n",
    "            \"trafficSource.adwordsClickInfo.page\", \n",
    "            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n",
    "            \"trafficSource.keyword\", \"trafficSource.medium\", \n",
    "            \"trafficSource.referralPath\", \"trafficSource.source\",\n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']\n",
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n",
    "train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype(float)\n",
    "\n",
    "num_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits']    \n",
    "for col in num_cols:\n",
    "    train_df[col] = train_df[col].astype(float)\n",
    "    test_df[col] = test_df[col].astype(float)\n",
    "\n",
    "# Split the train dataset into development and valid based on time \n",
    "#train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n",
    "dev_df = train_df[train_df['date']<=20170531]\n",
    "val_df = train_df[train_df['date']>2017531]\n",
    "dev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)\n",
    "\n",
    "dev_X = dev_df[cat_cols + num_cols] \n",
    "val_X = val_df[cat_cols + num_cols] \n",
    "test_X = test_df[cat_cols + num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dev_X, dev_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>geoNetwork.city</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>geoNetwork.metro</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>geoNetwork.region</th>\n",
       "      <th>geoNetwork.subContinent</th>\n",
       "      <th>trafficSource.adContent</th>\n",
       "      <th>trafficSource.adwordsClickInfo.adNetworkType</th>\n",
       "      <th>trafficSource.adwordsClickInfo.gclId</th>\n",
       "      <th>trafficSource.adwordsClickInfo.page</th>\n",
       "      <th>trafficSource.adwordsClickInfo.slot</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>trafficSource.adwordsClickInfo.isVideoAd</th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>totals.bounces</th>\n",
       "      <th>totals.newVisits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85573</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>459</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>78</td>\n",
       "      <td>7450</td>\n",
       "      <td>318</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>8098</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>626</td>\n",
       "      <td>2</td>\n",
       "      <td>1386</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.480437e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35822</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>317</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>7970</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>8098</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.493707e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80607</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>3206</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>8098</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.471878e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>459</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>8098</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1386</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.472838e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87560</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>8098</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.489842e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channelGrouping  device.browser  device.deviceCategory  \\\n",
       "85573                1              12                      0   \n",
       "35822                2              12                      0   \n",
       "80607                2              12                      1   \n",
       "875                  4              12                      0   \n",
       "87560                2              12                      1   \n",
       "\n",
       "       device.operatingSystem  geoNetwork.city  geoNetwork.continent  \\\n",
       "85573                      17              459                     2   \n",
       "35822                      17              317                     4   \n",
       "80607                       1                0                     2   \n",
       "875                         3              459                     2   \n",
       "87560                       1                0                     2   \n",
       "\n",
       "       geoNetwork.country  geoNetwork.metro  geoNetwork.networkDomain  \\\n",
       "85573                 190                78                      7450   \n",
       "35822                  58                 0                      7970   \n",
       "80607                 142                 0                      3206   \n",
       "875                   190                78                         0   \n",
       "87560                 190                 0                      4047   \n",
       "\n",
       "       geoNetwork.region  geoNetwork.subContinent  trafficSource.adContent  \\\n",
       "85573                318                       12                       47   \n",
       "35822                124                       22                       47   \n",
       "80607                  0                       15                       47   \n",
       "875                  318                       12                       47   \n",
       "87560                  0                       12                       47   \n",
       "\n",
       "       trafficSource.adwordsClickInfo.adNetworkType  \\\n",
       "85573                                             3   \n",
       "35822                                             3   \n",
       "80607                                             3   \n",
       "875                                               3   \n",
       "87560                                             3   \n",
       "\n",
       "       trafficSource.adwordsClickInfo.gclId  \\\n",
       "85573                                  8098   \n",
       "35822                                  8098   \n",
       "80607                                  8098   \n",
       "875                                    8098   \n",
       "87560                                  8098   \n",
       "\n",
       "       trafficSource.adwordsClickInfo.page  \\\n",
       "85573                                    6   \n",
       "35822                                    6   \n",
       "80607                                    6   \n",
       "875                                      6   \n",
       "87560                                    6   \n",
       "\n",
       "       trafficSource.adwordsClickInfo.slot  trafficSource.campaign  \\\n",
       "85573                                    3                      10   \n",
       "35822                                    3                       3   \n",
       "80607                                    3                       3   \n",
       "875                                      3                       3   \n",
       "87560                                    3                       3   \n",
       "\n",
       "       trafficSource.keyword  trafficSource.medium  \\\n",
       "85573                    626                     2   \n",
       "35822                    626                     0   \n",
       "80607                    626                     0   \n",
       "875                        5                     5   \n",
       "87560                    626                     0   \n",
       "\n",
       "       trafficSource.referralPath  trafficSource.source  \\\n",
       "85573                        1386                    16   \n",
       "35822                        1386                     0   \n",
       "80607                        1386                     0   \n",
       "875                          1386                    74   \n",
       "87560                        1386                     0   \n",
       "\n",
       "       trafficSource.adwordsClickInfo.isVideoAd  trafficSource.isTrueDirect  \\\n",
       "85573                                         1                           1   \n",
       "35822                                         1                           0   \n",
       "80607                                         1                           0   \n",
       "875                                           1                           1   \n",
       "87560                                         1                           0   \n",
       "\n",
       "       totals.hits  totals.pageviews  visitNumber  visitStartTime  \\\n",
       "85573          1.0               1.0          1.0    1.480437e+09   \n",
       "35822          2.0               2.0          1.0    1.493707e+09   \n",
       "80607          5.0               5.0          1.0    1.471878e+09   \n",
       "875           18.0              12.0          1.0    1.472838e+09   \n",
       "87560          1.0               1.0          1.0    1.489842e+09   \n",
       "\n",
       "       totals.bounces  totals.newVisits  \n",
       "85573             1.0               1.0  \n",
       "35822             0.0               1.0  \n",
       "80607             0.0               1.0  \n",
       "875               0.0               1.0  \n",
       "87560             1.0               1.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "val_pred = reg.predict(X_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3322613937319503"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-2a729c880d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_pred_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"fullVisitorId\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fullVisitorId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"transactionRevenue\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"totals.transactionRevenue\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PredictedRevenue\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred_val[pred_val<0] = 0\n",
    "val_pred_df = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\n",
    "val_pred_df[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\n",
    "val_pred_df[\"PredictedRevenue\"] = np.expm1(pred_val)\n",
    "#print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))\n",
    "val_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "train_df[\"revenue_cat\"] = pd.cut(train_df[\"totals.transactionRevenue\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(train_df, train_df[\"revenue_cat\"]):\n",
    "    strat_train_set = train_df.loc[train_index]\n",
    "    strat_test_set = train_df.loc[test_index]\n",
    "    \n",
    "\n",
    "#for set_ in (strat_train_set, strat_test_set):\n",
    " #   set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "strat_train_set = strat_train_set.drop(['revenue_cat'], axis=1)\n",
    "strat_test_set= strat_test_set.drop(['revenue_cat'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that there appears to be no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payingCustomers = train.loc[train['totals.transactionRevenue'].notna()]\n",
    "payingCustomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payingCustomers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1399 entries, 752 to 99743\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                        Non-Null Count  Dtype \n",
      "---  ------                                        --------------  ----- \n",
      " 0   channelGrouping                               1399 non-null   object\n",
      " 1   date                                          1399 non-null   int64 \n",
      " 2   fullVisitorId                                 1399 non-null   object\n",
      " 3   sessionId                                     1399 non-null   object\n",
      " 4   socialEngagementType                          1399 non-null   object\n",
      " 5   visitId                                       1399 non-null   int64 \n",
      " 6   visitNumber                                   1399 non-null   int64 \n",
      " 7   visitStartTime                                1399 non-null   int64 \n",
      " 8   device.browser                                1399 non-null   object\n",
      " 9   device.operatingSystem                        1399 non-null   object\n",
      " 10  device.isMobile                               1399 non-null   bool  \n",
      " 11  device.deviceCategory                         1399 non-null   object\n",
      " 12  geoNetwork.continent                          1399 non-null   object\n",
      " 13  geoNetwork.subContinent                       1399 non-null   object\n",
      " 14  geoNetwork.country                            1399 non-null   object\n",
      " 15  geoNetwork.region                             1399 non-null   object\n",
      " 16  geoNetwork.metro                              1399 non-null   object\n",
      " 17  geoNetwork.city                               1399 non-null   object\n",
      " 18  geoNetwork.networkDomain                      1399 non-null   object\n",
      " 19  totals.visits                                 1399 non-null   object\n",
      " 20  totals.hits                                   1399 non-null   object\n",
      " 21  totals.pageviews                              1399 non-null   object\n",
      " 22  totals.bounces                                0 non-null      object\n",
      " 23  totals.newVisits                              494 non-null    object\n",
      " 24  totals.transactionRevenue                     1399 non-null   object\n",
      " 25  trafficSource.campaign                        1399 non-null   object\n",
      " 26  trafficSource.source                          1399 non-null   object\n",
      " 27  trafficSource.medium                          1399 non-null   object\n",
      " 28  trafficSource.keyword                         448 non-null    object\n",
      " 29  trafficSource.isTrueDirect                    891 non-null    object\n",
      " 30  trafficSource.referralPath                    679 non-null    object\n",
      " 31  trafficSource.adwordsClickInfo.page           60 non-null     object\n",
      " 32  trafficSource.adwordsClickInfo.slot           60 non-null     object\n",
      " 33  trafficSource.adwordsClickInfo.gclId          61 non-null     object\n",
      " 34  trafficSource.adwordsClickInfo.adNetworkType  60 non-null     object\n",
      " 35  trafficSource.adwordsClickInfo.isVideoAd      60 non-null     object\n",
      " 36  trafficSource.adContent                       18 non-null     object\n",
      " 37  trafficSource.campaignCode                    0 non-null      object\n",
      "dtypes: bool(1), int64(4), object(33)\n",
      "memory usage: 416.7+ KB\n"
     ]
    }
   ],
   "source": [
    "payingCustomers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "json_cols = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "\n",
    "def load_df(csv_path='../input/train.csv', nrows=None):\n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in json_cols}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in json_cols:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (100000, 55)\n",
      "Loaded test.csv. Shape: (100000, 53)\n"
     ]
    }
   ],
   "source": [
    "train = load_df(nrows=100000, csv_path=\"data/train.csv\")\n",
    "test = load_df(\"data/test.csv\", 100000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just don't see how this works with a pipeline.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-101f442f1f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train[\"totals.transactionRevenue\"] = pd.cut(train[\"totals.transactionRevenue\"],\n\u001b[0m\u001b[0;32m      4\u001b[0m                                \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                labels=[1, 2])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\tile.py\u001b[0m in \u001b[0;36mcut\u001b[1;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bins must increase monotonically.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     fac, bins = _bins_to_cuts(\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[0mside\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"left\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mright\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"right\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "train[\"totals.transactionRevenue\"] = pd.cut(train[\"totals.transactionRevenue\"],\n",
    "                               bins=[0., np.inf],\n",
    "                               labels=[1, 2])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(train, train[\"totals.transactionRevenue\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer for removing unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class FeatureReducer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer for flattening the JSON features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonFlattener(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, json_cols):\n",
    "        self.json_cols = json_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for col in json_cols:\n",
    "            col_df = json_normalize(df[column])\n",
    "            col_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in col_df.columns]\n",
    "            X = X.drop(col, axis=1).merge(col_df, right_index=True, left_index=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "train[\"totals.transactionRevenue\"] = pd.cut(train[\"totals.transactionRevenue\"],\n",
    "                               bins=[0., np.inf],\n",
    "                               labels=[1, 2])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(train, train[\"totals.transactionRevenue\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all columns which need to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['socialEngagementType',\n",
       " 'totals.visits',\n",
       " 'trafficSource.campaignCode',\n",
       " 'sessionId']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_cols = [col for col in train.columns \n",
    "                if train[col].isna().all() \n",
    "                or train[col].eq(\"not available in demo dataset\").all()\n",
    "                or train[col].nunique(dropna=False)==1]\n",
    "useless_cols = useless_cols + [\"trafficSource.campaignCode\"] + [\"sessionId\"]\n",
    "useless_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare columns which need to be flattened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_cols = ['device', 'geoNetwork', 'totals', 'trafficSource']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"channelGrouping\", \"device.browser\", \n",
    "            \"device.deviceCategory\", \"device.operatingSystem\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n",
    "            \"trafficSource.adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource.adwordsClickInfo.gclId\", \n",
    "            \"trafficSource.adwordsClickInfo.page\", \n",
    "            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n",
    "            \"trafficSource.keyword\", \"trafficSource.medium\", \n",
    "            \"trafficSource.referralPath\", \"trafficSource.source\",\n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_pipeline = Pipeline([\n",
    "    ('flatten', JsonFlattener(json_cols)),\n",
    "    ('reduce', FeatureReducer(useless_cols))\n",
    "])\n",
    "\n",
    "label_encoding_pipeline = Pipeline([\n",
    "    (\"encode_labels\", ColumnTransformer(\n",
    "        (\"label_transformer\", LabelEncoder(), categorical_cols)\n",
    "    ))\n",
    "])\n",
    "\n",
    "impute_values_pipeline = Pipeline([\n",
    "    \n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    prepare_data_pipeline,\n",
    "    label_encoding_pipeline,\n",
    "    impute_values_pipeline\n",
    "])\n",
    "\n",
    "train_pipeline = Pipeline([\n",
    "    full_pipeline,\n",
    "    (\"impute_revenue\", ColumnTransformer(\n",
    "        ('revenue_imputer', SimpleImputer(strategy=\"constant\", fill_value=0), \"totals.transactionRevenue\")\n",
    "    ))\n",
    "])\n",
    "\n",
    "## Temp\n",
    "some_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "some_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"constant\", fill_value=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "Impute missing values\n",
    "    Set revnue to 0 if not present\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0   channelGrouping                               100000 non-null  object\n",
    "* 1   date                                          100000 non-null  int64 \n",
    "- 2   fullVisitorId                                 100000 non-null  object\n",
    "- 3   sessionId                                     100000 non-null  object\n",
    " 4   socialEngagementType                          100000 non-null  object\n",
    "- 5   visitId                                       100000 non-null  int64 \n",
    " 6   visitNumber                                   100000 non-null  int64 \n",
    "* 7   visitStartTime                                100000 non-null  int64 \n",
    " 8   device.browser                                100000 non-null  object\n",
    " 9   device.operatingSystem                        100000 non-null  object\n",
    " 10  device.isMobile                               100000 non-null  bool  \n",
    " 11  device.deviceCategory                         100000 non-null  object\n",
    " 12  geoNetwork.continent                          100000 non-null  object\n",
    " 13  geoNetwork.subContinent                       100000 non-null  object\n",
    " 14  geoNetwork.country                            100000 non-null  object\n",
    " 15  geoNetwork.region                             100000 non-null  object\n",
    " 16  geoNetwork.metro                              100000 non-null  object\n",
    " 17  geoNetwork.city                               100000 non-null  object\n",
    "* 18  geoNetwork.networkDomain                      100000 non-null  object\n",
    " 19  totals.visits                                 100000 non-null  object\n",
    " 20  totals.hits                                   100000 non-null  object\n",
    " 21  totals.pageviews                              99993 non-null   object\n",
    " 22  totals.bounces                                48916 non-null   object\n",
    " 23  totals.newVisits                              77263 non-null   object\n",
    " 24  totals.transactionRevenue                     1399 non-null    object\n",
    " 25  trafficSource.campaign                        100000 non-null  object\n",
    " 26  trafficSource.source                          100000 non-null  object\n",
    " 27  trafficSource.medium                          100000 non-null  object\n",
    " 28  trafficSource.keyword                         44218 non-null   object\n",
    " 29  trafficSource.isTrueDirect                    30454 non-null   object\n",
    " 30  trafficSource.referralPath                    36473 non-null   object\n",
    " 31  trafficSource.adwordsClickInfo.page           2574 non-null    object\n",
    " 32  trafficSource.adwordsClickInfo.slot           2574 non-null    object\n",
    " 33  trafficSource.adwordsClickInfo.gclId          2625 non-null    object\n",
    " 34  trafficSource.adwordsClickInfo.adNetworkType  2574 non-null    object\n",
    " 35  trafficSource.adwordsClickInfo.isVideoAd      2574 non-null    object\n",
    " 36  trafficSource.adContent                       1325 non-null    object\n",
    " 37  trafficSource.campaignCode                    1 non-null       object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"geoNetwork.networkDomain\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payingCustomers[\"totals.transactionRevenue\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payingCustomers[\"totals.transactionRevenue\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payingCustomers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Suggestion for deployment: Write a web API which can receive data like one or more rows from the test dataset and return a prediction for that data. We are thinking the client will send the data as JSON and receive a JSON response.\n",
    "\n",
    "In order to make this happen, we will need to have a way to transform our data to JSON format, as well as a way to transform it back to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[100000 rows x 0 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160902</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160902</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160902</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>1472865386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160902</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>1</td>\n",
       "      <td>1472881213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160902</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>2</td>\n",
       "      <td>1472822600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date     visitId  visitNumber  visitStartTime\n",
       "0  20160902  1472830385            1      1472830385\n",
       "1  20160902  1472880147            1      1472880147\n",
       "2  20160902  1472865386            1      1472865386\n",
       "3  20160902  1472881213            1      1472881213\n",
       "4  20160902  1472822600            2      1472822600"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(np.number).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[100000 rows x 0 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler  \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeemsLikeOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                     handle_unknown='error'):\n",
    "            self.encoding = encoding\n",
    "            self.categories = categories\n",
    "            self.dtype = dtype\n",
    "            self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "\n",
    "            #OneHotEncoding all numerical values\n",
    "            if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "                template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                            \"or 'ordinal', got %s\")\n",
    "                raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "            if self.handle_unknown not in ['error', 'ignore']:\n",
    "                template = (\"handle_unknown should be either 'error' or \"\n",
    "                            \"'ignore', got %s\")\n",
    "                raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "            if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "                raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                                 \" encoding='ordinal'\")\n",
    "\n",
    "            X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "            n_samples, n_features = X.shape\n",
    "\n",
    "            #LabelEncoding all categorical values\n",
    "            self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "            for i in range(n_features):\n",
    "                le = self._label_encoders_[i]\n",
    "                Xi = X[:, i]\n",
    "                if self.categories == 'auto':\n",
    "                    le.fit(Xi)\n",
    "                else:\n",
    "                    valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                    if not np.all(valid_mask):\n",
    "                        if self.handle_unknown == 'error':\n",
    "                            diff = np.unique(Xi[~valid_mask])\n",
    "                            msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                                   \" during fit\".format(diff, i))\n",
    "                            raise ValueError(msg)\n",
    "                    le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "            self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "            return self\n",
    "\n",
    "    def transform(self, X):\n",
    "            X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "            n_samples, n_features = X.shape\n",
    "            X_int = np.zeros_like(X, dtype=np.int)\n",
    "            X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "            for i in range(n_features):\n",
    "                valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(X[~valid_mask, i])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during transform\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                    else:\n",
    "                        X_mask[:, i] = valid_mask\n",
    "                        X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "                X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "            if self.encoding == 'ordinal':\n",
    "                return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "            mask = X_mask.ravel()\n",
    "            n_values = [cats.shape[0] for cats in self.categories_]\n",
    "            n_values = np.array([0] + n_values)\n",
    "            indices = np.cumsum(n_values)\n",
    "\n",
    "            column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "            row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                    n_features)[mask]\n",
    "            data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "            out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                    shape=(n_samples, indices[-1]),\n",
    "                                    dtype=self.dtype).tocsr()\n",
    "            if self.encoding == 'onehot-dense':\n",
    "                return out.toarray()\n",
    "            else:\n",
    "                return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,feature_names):\n",
    "        self.feature_names = feature_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.feature_names].values\n",
    "    \n",
    "\n",
    "# build pipelines\n",
    "cat_attribs = [\"channelGrouping\", \"device.browser\", \n",
    "            \"device.deviceCategory\", \"device.operatingSystem\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n",
    "            \"trafficSource.adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource.adwordsClickInfo.gclId\", \n",
    "            \"trafficSource.adwordsClickInfo.page\", \n",
    "            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n",
    "            \"trafficSource.keyword\", \"trafficSource.medium\", \n",
    "            \"trafficSource.referralPath\", \"trafficSource.source\",\n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']\n",
    "num_attribs = #all numerical attributes\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "               ('selector',DataFrameSelector(num_attribs)),      \n",
    "               ('std_scaler',StandardScaler()), \n",
    "                ]) \n",
    "\n",
    "# build categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "                  ('selector',DataFrameSelector(cat_attribs)),\n",
    "                  ('cat_encoder',CategoricalEncoder(encoding='onehot-dense')),\n",
    "              ])\n",
    "\n",
    "\n",
    "# merge all the transforms using \"FeatureUnion\"\n",
    "pipelines = FeatureUnion(transformer_list=\n",
    "                             [ \n",
    "                              ('num_pipeline',num_pipeline),\n",
    "                              ('cat_pipeline',cat_pipeline),\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Nov/2020 14:23:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Nov/2020 14:23:31] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "from flask import request\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"<h1>API for Google store revenue predictions</h1>\"\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    \n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO/Checklist\n",
    "\n",
    "* Create pipeline\n",
    "    * Create transformers for:\n",
    "        * Remove useless columns\n",
    "        * Impute missing values\n",
    "        * Transform total revenue to natural log of total revenue\n",
    "        \n",
    "        \n",
    "* Test the model to make sure it performs well-ish\n",
    "        \n",
    "* Store model to a file using pickle or joblib\n",
    "    \n",
    "    \n",
    "\n",
    "* Create API - The API will receive raw data in the same format as our initial CSV files. It will then have to:\n",
    "    * Remove missing columns\n",
    "    * impute missing values\n",
    "    * any other preprocessing\n",
    "    * Make prediction\n",
    "    * Return a JSON object containing customer ID and transactionrevenue. \n",
    "* Test API\n",
    "   \n",
    "We might start by only accepting single row data and then expand to allow multiple row data. \n",
    "\n",
    "### If we have time:\n",
    "* Display data in nice ways to gain insights\n",
    "* Try different models\n",
    "* Deploy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
